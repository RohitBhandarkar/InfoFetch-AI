{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying URL: https://computer.com/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'HOME - Computer.Com Skip to content Products Edge Network Infrastructure as a Service Platform as a Service Virtual & Dedicated Servers Video Streaming Platform Security AI & Machine Learning Cloud for Mobile Custom Services Edge Network CDN Next-gen CDN for dynamic and static content delivery Image Stack Dynamic image optimization: WebP, AVIF, cropping, resizing DNS Hosting Managed DNS service for mission-critical availability Cloud Storage S3-compatible storage for cloud-native environment Public DNS Fast, secure, and free DNS resolver that protects your privacy. Network Map Reliable global infrastructure for utmost service availability Edge Network All-in-one edge platform for better application delivery Pricing Choose the billing plan that suits your business needs Cloud Products Cloud Edge Services All-in-one edge platform for better application delivery Virtual Instances Virtual machines with pay-as-you-go billing and customizable configurations Computer Basic Shared virtual machines starting from 3.7 USD Bare Metal Single-tenant powerful physical servers for any business need Private Cloud Cloud networks with unlimited intra-network traffic SGX Instances with Intel Software Guard Extensions designed to build secure enclave-based applications. Cloud Storage S3/SFTP Storage for storing your data on our servers in United States, the USA, and Asia. Load Balancer Traffic distribution tool for increasing reliability and capacity of applications Data Migration Moving to our cloud without interruptions in the activity and zero data loss Disaster Recovery Protection of your business IT infrastructure from downtime in the event of failures and crashes CDN Content Delivery Network Secure Cloud Computing Secure Cloud Computing services help accelerate resilience in the public cloud by offering access to cloud security experts and strategies. Cloud File Shares Create, access, and share files remotely in the cloud Pricing Choose the billing plan that suits your business needs App Marketplace Online marketplace with ready-to-use applications Platform as a Service Managed Kubernetes Fully managed Kubernetes solution with no additional cost and rapid deployment Function as a Service Serverless computing service for running code in a ready-made environment Logging as a Service Collection of logs from all your servers in one repository Application Marketplace Online marketplace with ready-to-use applications Virtual & Dedicated Servers Hosting Virtual and Dedicated servers in certified data centers around the world Virtual Server Virtual servers with no traffic restrictions Dedicated Servers Physical servers in data centers on 4 continents SSL Certificates DV, OV, IDN, and Wildcard SSL certificates Additional Hosting Option IPs, VLAN, BGP, LACP Internet Options Internet connectivity plans GPU Dedicated Servers Physical servers with powerful graphics cards Video Streaming Platform Streaming Platform Infrastructure for streaming video in your apps to 100M+ viewers and beyond Video Hosting Media Platform by Computer.Com delivers video in 4K resolution to any device your viewers have Live-streaming Low latency streaming to 1,000,000+ viewers. Real Time Video Module for video calls and conferencing inside your web, iOS, and Android app Computer Vision Module for objects recognition and video analysis based on machine learning Features Tools you need to build & scale video streaming in seconds Pricing Streaming Platform plans and cost estimation calculator for your unique business case Security DDoS Protection Reliable infrastructure protection against DDoS attacks Web Application Security Web security mechanisms for stable application operation Secure Cloud Computing Computer.Com Secure Cloud Computing services help accelerate resilience in the public cloud by offering access to cloud security experts and strategies. WAAP Powerfull all-in-one WAAP (Web Application Firewall and API Protection) solution against full spectrum of threats Under Attack? If your website, server, or API is under attack â\\x80\\x94 we are ready to help Penetration Test IT infrastructure and web applications trial for penetration AI Products AI Infrastructure All-in-one AI Service AI Universities AI for Universities and Research teams AI GPU Cloud Bare metal servers and virtual machines with NVIDIA A100 and H100 GPUs Cloud for Mobile 5G eSIM platform Cloud computing powered by 5G eSIM technology Custom Services Products IT Infrastructure Management Services that cover all the IT needs â\\x80\\x93 from architecture planning to the operation of ready-made solutions Penetration Test IT infrastructure and web applications trial for penetration White Label Program White-label edge and cloud services ready-to-rock with your logo and branding Premium Support Experienced and friendly technical support specialists to assist in connecting, integrating, configuring and maintaining. Software Development Full-cycle development without the need to hire programmers Solutions Solutions By Industry By Need By Service Gaming CDN for Gaming Game Server Protection Media & Entertainment CDN for Video Video Hosting Live Streaming Video Calls Metaverse Streaming Low Latency Broadcasting Financial Services Cloud for financial services IT / Technology Image Optimization Website Acceleration WordPress CDN White Label Program Retail CDN for E-commerce Education AI Universities Online Education Web Acceleration Website Acceleration Image Optimization Wordpress CDN Video Streaming CDN for Video Video Hosting Live Streaming Video Calls Security & Protection DDoS Protection Game Server Protection Penetration Test Cloud Web Service Availability Multi-CDN Partnership Solutions White Label Products Affiliate Program Referral Program Corporate Solutions Data Migration Disaster Recovery Cloud Cloud Service Cloud Products Cloud Edge Services All-in-one edge platform for better application delivery Virtual Instances Virtual machines with pay-as-you-go billing and customizable configurations Computer Basic Shared virtual machines starting from 3.7 USD Bare Metal Single-tenant powerful physical servers for any business need Private Cloud Cloud networks with unlimited intra-network traffic SGX Instances with Intel Software Guard Extensions designed to build secure enclave-based applications. Cloud Storage S3/SFTP Storage for storing your data on our servers in United States, the USA, and Asia. Load Balancer Traffic distribution tool for increasing reliability and capacity of applications Data Migration Moving to our cloud without interruptions in the activity and zero data loss Disaster Recovery Protection of your business IT infrastructure from downtime in the event of failures and crashes CDN Content Delivery Network Secure Cloud Computing Secure Cloud Computing services help accelerate resilience in the public cloud by offering access to cloud security experts and strategies. Cloud File Shares Create, access, and share files remotely in the cloud Pricing Choose the billing plan that suits your business needs App Marketplace Online marketplace with ready-to-use applications AI/ML Infrastructure AI Service AI Products AI Infrastructure All-in-one AI Service AI Universities AI for Universities and Research teams AI GPU Cloud Bare metal servers and virtual machines with NVIDIA A100 and H100 GPUs Company About Compliance Press & Media Legal Information Careers Internet Peering Points X AI Assistant Products Edge Network CDN Multi-CDN Image Stack DNS Hosting Storage Public DNS Network EdgeÂ\\xa0Network Edge Network Pricing Infrastructure as a Service Cloud Virtual Instances Computer Basic Bare Metal Private Cloud Cloud File Shares SGX Cloud Storage Load Balancer Data Migration Disaster Recovery CDN Secure Cloud Computing Pricing App Marketplace Platform as a Service Managed Kubernetes Function as a Service Logging as a Service Application Marketplace Virtual & Dedicated Servers Hosting Virtual Server Dedicated Servers SSL Certificates Additional Hosting Option Internet Options GPU Dedicated Servers Video Streaming Platform Streaming Platform Video Hosting Live-streaming Real Time Video Computer Vision Features Pricing Security DDoS Protection Web Application Security Secure Cloud Computing Web Application Firewall & API Protection Penetration Test Under Attack? AI & Machine Learning Ai Infrastructure AI Universities AI GPU Cloud Cloud for Mobile 5G eSIM platform Custom Services Products IT Infrastructure Management Penetration Test White Label Program Premium Support Software Development Solutions By Industry Gaming Video CDN Video Hosting Live Streaming Video Calls Metaverse Streaming Low Latency Broadcasting Financial Services Image Stack Website Acceleration WordPress CDN White Label Program E-commerce AI Universitie Online Education By Need Website Acceleration Image Optimization Video CDN Video Hosting Live Streaming Video Calls DDoS Protection Penetration Test By Service White Label Products Affiliate Program Referral Program Data Migration Disaster Recovery Company About Compliance Press & Media Legal Information Careers Internet Peering X Embedded Chatbox Computer.Com AI Chat Bot â\\x96¡ - x Server configurator $ Region US South America Europe Asia Australia MENA Africa Data Centers in US * Miami Santa Clara Ashburn,DC 2 Chicago Los Angeles Atlanta Minneapolis Data Centers in Australia * Sydney Data Centers in Africa * Johannesburg Data Centers in MENA * Tel Aviv Data Centers in Europe * Bucharest Budapest Frankfurt Kyiv London Luxembourg Madrid Milan Paris Warsaw Data Centers in South America * Fortaleza Lima SÃ£o Paulo Data centers at asia * Almaty Seoul Singapore Hong Kong Tokyo Yerevan Duration * Select Option 1 Month 6 Month 12 Month CPU * 1 vCPU [+$10.00] 2 vCPU [+$20.00] 4 vCPU [+$40.00] 6 vCPU [+$60.00] 7 vCPU [+$70.00] 8 vCPU [+$80.00] CPU * 1 vCPU [+$60.00] 2 vCPU [+$120.00] 4 vCPU [+$240.00] 6 vCPU [+$360.00] 7 vCPU [+$420.00] 8 vCPU [+$480.00] CPU * 1 vCPU [+$120.00] 2 vCPU [+$240.00] 4 vCPU [+$480.00] 6 vCPU [+$720.00] 7 vCPU [+$840.00] 8 vCPU [+$960.00] RAM * 512 Mb [+$2.50] 1 GB [+$5.00] 2 GB [+$10.00] 4 GB [+$20.00] 6 GB [+$30.00] 8 GB [+$40.00] 16 GB [+$80.00] 32 GB [+$160.00] RAM * 512 Mb [+$15.00] 1 GB [+$30.00] 2 GB [+$60.00] 4 GB [+$120.00] 6 GB [+$180.00] 8 GB [+$240.00] 16 GB [+$480.00] 32 GB [+$960.00] RAM * 512 Mb [+$30.00] 1 GB [+$60.00] 2 GB [+$120.00] 4 GB [+$240.00] 6 GB [+$360.00] 8 GB [+$480.00] 16 GB [+$960.00] 32 GB [+$1,920.00] Disk * 20 Gb [+$4.00] 30 Gb [+$6.00] 50 Gb [+$10.00] 100 Gb [+$20.00] 200 Gb [+$40.00] 400 Gb [+$80.00] 600 Gb [+$120.00] Disk * 20 Gb [+$24.00] 30 Gb [+$36.00] 50 Gb [+$60.00] 100 Gb [+$120.00] 200 Gb [+$240.00] 400 Gb [+$480.00] 600 Gb [+$720.00] Disk * 20 Gb [+$48.00] 30 Gb [+$72.00] 50 Gb [+$120.00] 100 Gb [+$240.00] 200 Gb [+$480.00] 400 Gb [+$960.00] 600 Gb [+$1,440.00] Type * SSD OS * Linux Windows VM Configator quantity Add to cart Empowering your life with intelligent virtual assistants From creating better customer experiences on your website to monitoring your residential space for safety, the practical possibilities of computer vision AI are endless Digital business AI The most of artificial intelligence by applying it to strategic digital business. Snap and Search Host your GPU-intensive applications with ease Identify Human Behavior our reliable GPU hosting service provides the ultimate platform for your high-performance computing needs. Latest post. Donâ\\x80\\x99t miss it. View more articles The best prices for cloud GPUs & IPUs. Unleash the power of AI with our lightning-fast GPU & IPU servers - experience the future of computing with us Sing up for free Sing in > Take advantage of Computer.Com Cloud solutions AI IPU Use Computer.Com’s AI cloud infrastructure powered by Graphcore IPUs to accelerate machine learning. Explore details Bare metal servers Deploy resource-intensive applications and services on high-performance physical servers. Explore details Virtual machines Leverage production-grade VMs designed for a wide range of workloads and predictable performance. Explore details Managed Kubernetes Provision, manage, and scale Kubernetes clusters with 99.9% SLA and support for bare metal nodes. Explore details GPU and IPU Cloud GPUs & IPUs from $0.50/hour > _ _ _ The ultimate GPU & IPU server for deep learning Now available with NVIDIA H100 Tensor Core GPUs & IPUs Get pricing SPEND LESS Instant access to cloud GPUs at the best prices Save over 73% on your cloud bill Get the latest NVIDIA GPUs for the best prices on the market. Pay-by-the-second billing Only pay when your instance is running. Simple, transparent pricing No hidden fees like data egress or ingress. Sing up for free Engineered for your workload Tell us about your research and we’ll design a machine that’s perfectly tailored to your needs. Talk to an Expert Contact us to get an individual quote Tell us about your business challenges, and we will help you to find the right solution for better growth. Talk to an Expert View pricing Contact support@computer.com info@computer.com Sales Sales: +1.646.808.3999 sales@computer.com Products Virtual Instances Cloud Storage AI Infrastructure Resources Status Page API Documentation API Documentation Humberger Toggle Menu Products Virtual Instances Cloud Storage AI Infrastructure Resources Status Page API Documentation Knowledge Base Contact support@computer.com info@computer.com Sales Sales: +1.813.970.0555 sales@computer.com Subscribe to our newsletter Submit This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply. Computer.Com Ltd. Â© 2024.Â Login with Computer.Com Which service you want? Basic VM Or Bare Metal Next-Gen WAF API protection Average cost Next-Gen WAF Next-Gen WAFNext-Gen WAF (NG-WAF) is an updated, robust protection system to keep your web resources safe from even the most sophisticated attacks, including cross-site scripting (XSS), SQL injection (SQLi) and denial of service (DoS) attacks. NG-WAFs augment your defenses to support both your internal operations and your customers.Book Demo API protection API protectionIts API protection comprises a combination of tools for access control, data breach prevention, and DoS attack mitigation. It provides potent protection against a growing number of API security threats not covered by traditional WAFs.Book Demo Average cost Average costThe average cost of a single data breach across all industries worldwide stands at over USD $4 million as of April 2023, according to Statista. In 2023, Web Application Firewalls (WAFs) alone are not enough to protect your business. Instead, you need WAF and API Protection, now available from Gcore in one ready-to-use, powerful solution.Book Demo\\n\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from googlesearch import search\n",
    "\n",
    "def get_content_from_url(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        # Remove script and style elements\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "        # Get text content\n",
    "        text = soup.get_text()\n",
    "        # Clean up whitespace\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        text = ' '.join(chunk for chunk in chunks if chunk)\n",
    "        return text\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "topic = input(\"Enter a topic to search: \")\n",
    "content = \"\"\n",
    "\n",
    "# Get first 3 search results\n",
    "for url in search(topic, num_results=3):\n",
    "    print(url)\n",
    "    content += get_content_from_url(url) + \"\\n\\n\"\n",
    "\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning/Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned text:\n",
      " What Is NLP (Natural Language Processing)? | IBM Home Topics Natural language processing What is NLP (natural language processing)? Learn about IBM's NLP solutions Sign up for AI updates Updated: 11 August 2024 Contributor: Cole Stryker, Jim Holdsworth What is NLP? Natural language processing (NLP) is a subfield of computer science and artificial intelligence (AI) that uses machine learning to enable computers to understand and communicate with human language. NLP enables computers and digital d\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"\\[.*?\\]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "cleaned_data = clean_text(content)\n",
    "print(\"Cleaned text:\\n\", cleaned_data[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109961"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge base using sentence embenddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rohitb/projects/InfoFetch/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 62 chunks.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss # Facebook AI Similarity Seacrh\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "chunks = [cleaned_data[i:i+500] for i in range(0, len(cleaned_data), 500)] # chunking\n",
    "embeddings = model.encode(chunks) # embeddings for each chunk\n",
    "# embeddings array of the form (N,D) where N = no. of chunks and D = dim of embeddings vec\n",
    "\n",
    "\n",
    "dimension = embeddings.shape[1] # extract D\n",
    "index = faiss.IndexFlatL2(dimension) # initialize L2 eucidean distance for similarity b/w vecs; saying it has dimension number of dimensions for the vectors\n",
    "index.add(np.array(embeddings)) # add embeddings to FAISS index; FAISS build internal struct for optimal search\n",
    "print(f\"Indexed {len(chunks)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is natural language processing?\n",
      "Answer: providing computers with the ability to process data encoded in natural language\n"
     ]
    }
   ],
   "source": [
    "def find_closest_chunk(question):\n",
    "    question_embedding = model.encode([question])\n",
    "    _, closest_index = index.search(np.array(question_embedding), 1)\n",
    "    return chunks[closest_index[0][0]]\n",
    "\n",
    "def answer_question(question):\n",
    "    context = find_closest_chunk(question)\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    return result['answer']\n",
    "\n",
    "question = \"what is natural language processing?\"\n",
    "answer = answer_question(question)\n",
    "print(f\"Question: {question}\\nAnswer: {answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# proper RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"What is Natural Language Processing?\"\n",
    "\n",
    "query_embedding = model.encode([user_query])\n",
    "D, I = index.search(query_embedding, k=10)  # top 5\n",
    "\n",
    "relevant_passages = [chunks[i] for i in I[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics. Typically data is collected in text corpora, using either rule-based, statistical or neural-based approaches in machine learning and deep learn',\n",
       " ' can be derived from a natural language expression which usually takes the form of organized notations of natural language concepts. Introduction and creation of language metamodel and ontology are efficient however empirical solutions. An explicit formalization of natural language semantics without confusions with implicit assumptions such as closed-world assumption (CWA) vs. open-world assumption, or subjective Yes/No vs. objective True/False is expected for the construction of a basis of sema',\n",
       " 'ing. Major tasks in natural language processing are speech recognition, text classification, natural-language understanding, and natural-language generation. == History == Natural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligence',\n",
       " 'y of this task depends greatly on the complexity of the morphology (i.e., the structure of words) of the language being considered. English has fairly simple morphology, especially inflectional morphology, and thus it is often possible to ignore this task entirely and simply model all possible forms of a word (e.g., \"open, opens, opened, opening\") as separate words. In languages such as Turkish or Meitei, a highly agglutinated Indian language, however, such an approach is not possible, as each d',\n",
       " \"ance of quantitative evaluation in this period. === Statistical NLP (1990s–2010s) === Up until the 1980s, most natural language processing systems were based on complex sets of hand-written rules. Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing. This was due to both the steady increase in computational power (see Moore's law) and the gradual lessening of the dominance of Chomsk\",\n",
       " 'ology, syntax and certain aspects of semantics are concerned, and due to the development of powerful neural language models such as GPT-2, this can now (2019) be considered a largely solved problem and is being marketed in various commercial applications. Logic translation Translate a text from a natural language into formal logic. Machine translation (MT) Automatically translate text from one human language to another. This is one of the most difficult problems, and is a member of a class of pr',\n",
       " 'oblems colloquially termed \"AI-complete\", i.e. requiring all of the different types of knowledge that humans possess (grammar, semantics, facts about the real world, etc.) to solve properly. Natural-language understanding (NLU) Convert chunks of text into more formal representations such as first-order logic structures that are easier for computer programs to manipulate. Natural language understanding involves the identification of the intended semantic from the multiple possible semantics which',\n",
       " 'f these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks. Though natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below. === Text and speech processing === Optical character recognition (OCR) Given an image representing printed text, determine the corresponding text. Speech recognition Given a sound clip of a person or pe',\n",
       " \"ntics formalization. Natural-language generation (NLG): Convert information from computer databases or semantic intents into readable human language. Book generation Not an NLP task proper but an extension of natural language generation and other NLP tasks is the creation of full-fledged books. The first machine-generated book was created by a rule-based system in 1984 (Racter, The policeman's beard is half-constructed). The first published work by a neural network was published in 2018, 1 the R\",\n",
       " 'word embeddings to capture semantic properties of words. Intermediate tasks (e.g., part-of-speech tagging and dependency parsing) are not needed anymore. Neural machine translation, based on then-newly-invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation. == Common NLP tasks == The following is a list of some of the most commonly researched tasks in natural language processing. Some o']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_passages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_passages_str = ''.join(relevant_passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics. Typically data is collected in text corpora, using either rule-based, statistical or neural-based approaches in machine learning and deep learn can be derived from a natural language expression which usually takes the form of organized notations of natural language concepts. Introduction and creation of language metamodel and ontology are efficient however empirical solutions. An explicit formalization of natural language semantics without confusions with implicit assumptions such as closed-world assumption (CWA) vs. open-world assumption, or subjective Yes/No vs. objective True/False is expected for the construction of a basis of semaing. Major tasks in natural language processing are speech recognition, text classification, natural-language understanding, and natural-language generation. == History == Natural language processing has its roots in the 1950s. Already in 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence, though at the time that was not articulated as a problem separate from artificial intelligencey of this task depends greatly on the complexity of the morphology (i.e., the structure of words) of the language being considered. English has fairly simple morphology, especially inflectional morphology, and thus it is often possible to ignore this task entirely and simply model all possible forms of a word (e.g., \"open, opens, opened, opening\") as separate words. In languages such as Turkish or Meitei, a highly agglutinated Indian language, however, such an approach is not possible, as each dance of quantitative evaluation in this period. === Statistical NLP (1990s–2010s) === Up until the 1980s, most natural language processing systems were based on complex sets of hand-written rules. Starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing. This was due to both the steady increase in computational power (see Moore\\'s law) and the gradual lessening of the dominance of Chomskology, syntax and certain aspects of semantics are concerned, and due to the development of powerful neural language models such as GPT-2, this can now (2019) be considered a largely solved problem and is being marketed in various commercial applications. Logic translation Translate a text from a natural language into formal logic. Machine translation (MT) Automatically translate text from one human language to another. This is one of the most difficult problems, and is a member of a class of problems colloquially termed \"AI-complete\", i.e. requiring all of the different types of knowledge that humans possess (grammar, semantics, facts about the real world, etc.) to solve properly. Natural-language understanding (NLU) Convert chunks of text into more formal representations such as first-order logic structures that are easier for computer programs to manipulate. Natural language understanding involves the identification of the intended semantic from the multiple possible semantics whichf these tasks have direct real-world applications, while others more commonly serve as subtasks that are used to aid in solving larger tasks. Though natural language processing tasks are closely intertwined, they can be subdivided into categories for convenience. A coarse division is given below. === Text and speech processing === Optical character recognition (OCR) Given an image representing printed text, determine the corresponding text. Speech recognition Given a sound clip of a person or pentics formalization. Natural-language generation (NLG): Convert information from computer databases or semantic intents into readable human language. Book generation Not an NLP task proper but an extension of natural language generation and other NLP tasks is the creation of full-fledged books. The first machine-generated book was created by a rule-based system in 1984 (Racter, The policeman\\'s beard is half-constructed). The first published work by a neural network was published in 2018, 1 the Rword embeddings to capture semantic properties of words. Intermediate tasks (e.g., part-of-speech tagging and dependency parsing) are not needed anymore. Neural machine translation, based on then-newly-invented sequence-to-sequence transformations, made obsolete the intermediate steps, such as word alignment, previously necessary for statistical machine translation. == Common NLP tasks == The following is a list of some of the most commonly researched tasks in natural language processing. Some o'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_passages_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install 'accelerate>=0.26.0'`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[1;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen/Qwen2.5-Coder-7B-Instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[1;32m     15\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     16\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: relevant_passages_str},\n\u001b[1;32m     17\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_query}\n\u001b[1;32m     18\u001b[0m ]\n",
      "File \u001b[0;32m~/projects/InfoFetch/venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/projects/InfoFetch/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3577\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3573\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3574\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with `low_cpu_mem_usage=True` or with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3575\u001b[0m         )\n\u001b[1;32m   3576\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[0;32m-> 3577\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m   3578\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccelerate>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mACCELERATE_MIN_VERSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3579\u001b[0m         )\n\u001b[1;32m   3581\u001b[0m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[1;32m   3582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[0;31mImportError\u001b[0m: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install 'accelerate>=0.26.0'`"
     ]
    }
   ],
   "source": [
    "# too heavy\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"Qwen/Qwen2.5-Coder-7B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"mps\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": relevant_passages_str},\n",
    "    {\"role\": \"user\", \"content\": user_query}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster on colab:\n",
    "# https://colab.research.google.com/drive/1D9i2py0A1Q09b8QzDymus_vWfL5HpW_o?usp=sharing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
